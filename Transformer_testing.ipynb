{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Transformer Testing\n",
    "\n",
    "Author: Kara Ponder (SLAC)\n",
    "\n",
    "This notebook was used to test and build the transformer model. It's contents have been put in a python script `transformer.py` but I'm including this in the repo if further model development is needed. \n",
    "\n",
    "This code was originally based on a Tensorflow Transformer example: https://www.tensorflow.org/text/tutorials/transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "d_model = 128  # input vector must have length d_model\n",
    "target_vocab_size = 6  # possible results to choose from\n",
    "\n",
    "lc_length = 100 +1 # light curve length\n",
    "input_vocab_size = lc_length\n",
    "\n",
    "## hyperparameters:\n",
    "num_layers = 8\n",
    "dropout_rate = 0.0\n",
    "dff = 64 # hidden layer size of the feed forward network, needs to be larger than 24\n",
    "num_heads = 8 # d_model % num_heads == 0\n",
    "\n",
    "# LC stuff\n",
    "N = 10000 # number of objects\n",
    "N_days = 100 + 1\n",
    "Nf = 6 # number of filters\n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was tested using the simplified data in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_data = np.load('lc_data.npy')\n",
    "wgt_map = np.load('weightmap.npy')\n",
    "real_lc_data = np.load('real_lc.npy')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((lc_data, real_lc_data, wgt_map))\n",
    "batch_ds = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions below are based on the Transformer tutorial but have been modified to work with light curve data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeaded Attention\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "       q, k, v must have matching leading dimensions.\n",
    "       k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "       The mask has different shapes depending on its type(padding or look ahead)\n",
    "       but it must be broadcastable for addition.\n",
    "\n",
    "       Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: Float tensor with shape broadcastable\n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "      Returns:\n",
    "       output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "           Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        r = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return r\n",
    "  \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "                                tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "                                tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "  \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output,\n",
    "                                               out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "                 maximum_position_encoding, rate=0.1, embed=False):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dff = dff\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "        self.rate = rate\n",
    "        self.embed = embed\n",
    "        \n",
    "        if self.embed:\n",
    "            self.embedding = tf.keras.layers.Dense(self.d_model) # linear embedding\n",
    "\n",
    "        self.pos_encoding = positional_encoding(self.maximum_position_encoding,\n",
    "                                                self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(self.d_model, self.num_heads, self.dff, self.rate)\n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(self.rate)\n",
    "\n",
    "    def call(self, x, training): #, mask):\n",
    "        mask = create_padding_mask(x[:,:, 0])\n",
    "        #print('mask', tf.shape(x))\n",
    "\n",
    "        if self.embed:\n",
    "            x = self.embedding(x)\n",
    "        #print('after embed', x.shape)\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        #print('seq_len', seq_len)\n",
    "\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = tf.cast(x, dtype=tf.float32)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'num_layers': self.num_layers,\n",
    "                       'd_model': self.d_model, \n",
    "                       'num_heads': self.num_heads, \n",
    "                       'dff': self.dff, \n",
    "                       'maximum_position_encoding': self.maximum_position_encoding, \n",
    "                       'rate': self.rate,\n",
    "                       'embed': self.embed,\n",
    "                      })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                maximum_position_encoding, rate=0.1, embed=False):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dff = dff\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "        self.rate = rate\n",
    "        self.embed = embed\n",
    "        \n",
    "        if self.embed:\n",
    "            self.embedding = tf.keras.layers.Dense(self.d_model) # linear embedding\n",
    "\n",
    "        self.pos_encoding = positional_encoding(self.maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(self.d_model, self.num_heads, self.dff, self.rate)\n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(self.rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, mask): #, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        if self.embed:\n",
    "            x = self.embedding(x) \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   mask[0], mask[1])\n",
    "                                                   #look_ahead_mask, padding_mask)\n",
    "\n",
    "        attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "        attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x #, attention_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'num_layers': self.num_layers,\n",
    "                       'd_model': self.d_model, \n",
    "                       'num_heads': self.num_heads, \n",
    "                       'dff': self.dff, \n",
    "                       'target_vocab_size': self.target_vocab_size,\n",
    "                       'maximum_position_encoding': self.maximum_position_encoding, \n",
    "                       'rate': self.rate,\n",
    "                       'embed': self.embed,\n",
    "                      })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0.0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "def create_decoder_masks(inp, tar):  \n",
    "    inp = inp[:,:, 0]\n",
    "    tar = tar[:,:, 0]\n",
    "    \n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've defined all functions. Now we can start to  compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.00001)\n",
    "loss_object = tf.keras.losses.MeanSquaredError() #tf.keras.losses.MeanAbsoluteError() #\n",
    "\n",
    "class RMSE(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"rmse\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        print(y_true.shape, y_pred.shape)\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        return tf.math.sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                       lc_length, dropout_rate, embed=True)\n",
    "\n",
    "decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                        target_vocab_size, lc_length, dropout_rate, embed=True)\n",
    "\n",
    "final_layer = tf.keras.layers.Dense(target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.layers.Input(shape=(None,6))#shape=(None,None))# # None if d_model=6 with no embedding, 6 if using embedding\n",
    "target = tf.keras.layers.Input(shape=(None,6))#shape=(None,None))#\n",
    "wgts = tf.keras.layers.Input(shape=(None,6))\n",
    "\n",
    "x = encoder(inp)\n",
    "x = decoder(target, x, mask=create_decoder_masks(inp, target))\n",
    "x = final_layer(x)\n",
    "\n",
    "mx = tf.keras.layers.Multiply()([x, wgts])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[inp, target, wgts], outputs=mx) #[inp, target, wgts]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=RMSE(),\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either load in weights below or fit the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('some/saved/weights/transformer.h5')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 0\n",
    "for (batch, _) in enumerate(batch_ds):\n",
    "    num_batches = batch\n",
    "    \n",
    "#num_batches_VALID = 0\n",
    "#for (batch, (_,_)) in enumerate(batch_ds_VALID):\n",
    "#    num_batches_VALID = batch\n",
    "\n",
    "\n",
    "def generator(data_set):\n",
    "    while True:\n",
    "        for in_batch, tar_batch, wgt_batch in data_set:\n",
    "            yield ( [in_batch , in_batch[:, :-1, :], wgt_batch[:, 1:, :]] , in_batch[:, 1:, :])\n",
    "\n",
    "history = model.fit(x = generator(batch_ds),\n",
    "                    #validation_data = generator(batch_ds_VALID),\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch = num_batches,\n",
    "                    #validation_steps = num_batches_VALID,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('/sdf/home/k/kap146/desc/transformer/testing_tfmodel.h5')\n",
    "#model.save_weights('/sdf/home/k/kap146/desc/transformer/testing_tfmodel_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this doesn't work\n",
    "## crashes the kernel\n",
    "#@tf.function\n",
    "def evaluate(lc_data):\n",
    "    inp_lc = tf.expand_dims(lc_data, 0)\n",
    "    decoder_input=tf.constant([[-1.0]*Nf]) # tf.multiply(-1., tf.ones(Nf, dtype=tf.float64)) #\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(N_days):\n",
    "        predictions = model([inp_lc, output]) ## if batching may need predict..\n",
    "        \n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        output = tf.concat([output, predictions], axis=1)\n",
    "        \n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "check_lc = tf.constant(lc_data[1])\n",
    "inp_lc = tf.expand_dims(check_lc, 0)\n",
    "\n",
    "#start = time.time()\n",
    "#pred2=evaluate(check_lc)\n",
    "\n",
    "#print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "decoder_input=[[-1.0]*Nf]## or 0\n",
    "output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "for i in range(N_days-1):\n",
    "    predictions = model([lc_data[1][tf.newaxis, :, :], output]) #.predict\n",
    "    \n",
    "    predictions = predictions[: ,-1:, :] ## CHECKKK\n",
    "    \n",
    "    output = tf.concat([output, predictions], axis=1)\n",
    "    tf.squeeze(output, axis=0)\n",
    "\n",
    "print(time.time() - start) # 400s first time, # 6s after ## new:25s, 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "plt.plot(lc_data[i][1:], 'ro', ls = '-.', lw = 2, alpha=0.4)\n",
    "\n",
    "plt.plot(output[0][1:, 0], lw=2, label='predicted lc') # this might finally be right!\n",
    "plt.plot(output[0][1:, 1], lw=2)\n",
    "plt.plot(output[0][1:, 2], lw=2)\n",
    "plt.plot(output[0][1:, 3], lw=2)\n",
    "plt.plot(output[0][1:, 4], lw=2)\n",
    "plt.plot(output[0][1:, 5], lw=2)\n",
    "\n",
    "plt.plot(real_lc_data[i][:], 'k', ls = '--', lw = 2, alpha=0.4)\n",
    "plt.plot(real_lc_data[i][:][0], 'k', ls = '--', lw = 2, label='model lc') #, alpha=0.4)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('brightness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
