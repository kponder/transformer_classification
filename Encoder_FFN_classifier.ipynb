{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer-style Encoder + FFN ONLY\n",
    "\n",
    "This set up only uses the encoder piece of the Transformer and directly attatches it to a feed-forward network to go straight from light curves to classification.\n",
    "\n",
    "Not intended to be the primary algorithm. Similar to what is done in Allam et al (2021).\n",
    "\n",
    "Author: Kara Ponder (SLAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformer import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "d_model = 128  # input vector must have length d_model\n",
    "target_vocab_size = 6  # possible results to choose from\n",
    "\n",
    "lc_length = 100 +1 # light curve length\n",
    "input_vocab_size = lc_length\n",
    "\n",
    "## hyperparameters:\n",
    "num_layers = 8 \n",
    "dropout_rate = 0.0\n",
    "dff = 64 # hidden layer size of the feed forward network, needs to be larger than 24\n",
    "num_heads = 8  # d_model % num_heads == 0\n",
    "\n",
    "# LC stuff\n",
    "N = 10000 # number of objects\n",
    "N_days = 100 + 1\n",
    "Nf = 6 # number of filters\n",
    "num_classes = 4\n",
    "num_class = 4\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define FFN for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ffn(nclass, dff, rate=0.0):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(dff, activation='relu')) \n",
    "    model.add(tf.keras.layers.Dropout(rate))\n",
    "    model.add(tf.keras.layers.Dense(dff, activation='relu'))\n",
    "    model.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "    model.add(tf.keras.layers.Dense(nclass, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss fucntion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_kld(layer1, alpha=0.3):\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    layer1 = layer1[0]\n",
    "    layer1 = tf.math.abs(layer1)\n",
    "\n",
    "    ones = tf.ones(layer1.shape, dtype=tf.float32)\n",
    "    rhoc = 0.00001\n",
    "    rho = rhoc*ones\n",
    "\n",
    "    def kld(layer):\n",
    "        kld_1 = tf.math.multiply(rhoc, tf.math.log(tf.math.divide_no_nan(rho, layer)))\n",
    "        kld_2 = tf.math.multiply((1.0 - rhoc), tf.math.divide_no_nan(tf.math.log(ones-rho), tf.math.log(ones-layer)))\n",
    "        return tf.reduce_sum(kld_1 + kld_2)\n",
    "\n",
    "    return tf.multiply(alpha, kld(layer1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Encoder+FFN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                       lc_length, dropout_rate, embed=True)\n",
    "\n",
    "class_ffn = classify_ffn(num_classes, dff, rate=dropout_rate)\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(None, Nf), dtype=tf.float32)\n",
    "extras = tf.keras.layers.Input(shape=(None, 2), dtype=tf.float32) # min/max normalization constants\n",
    "\n",
    "x = encoder(inp)\n",
    "x = tf.keras.layers.Concatenate(axis=-1)([x, extras])\n",
    "x = class_ffn(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[inp, extras], outputs=x)\n",
    "model.add_loss(lambda x=model.get_layer(name='encoder').get_weights(): loss_kld(x))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.00001)\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "model.compile(loss=loss_object,\n",
    "                optimizer=optimizer, \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.load('label.npy')\n",
    "lc_data = np.load('lc_data.npy')\n",
    "norm_data = np.loadtxt('min_max.txt')\n",
    "\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(label, num_classes=num_class, dtype=\"float64\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((lc_data, labels, norm_data))\n",
    "batch_ds = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 0\n",
    "for (batch, (_,_)) in enumerate(batch_ds):\n",
    "    num_batches = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_set):\n",
    "    while True:\n",
    "        for in_batch, tar_batch, norm_batch in data_set:\n",
    "            yield ( [in_batch, norm_batch] , tar_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = generator(batch_ds),\n",
    "                    #validation_data = generator(batch_ds_VALID),\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch = num_batches,\n",
    "                    #validation_steps = num_batches_VALID,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('save_encoderffn_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
