{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN\n",
    "\n",
    "Intended as a baseline for the Transformer. Based on the original classifier from RAPID, Muthukrishna et al (2019)\n",
    "\n",
    "Author: Kara Ponder (SLAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.layers import Dense, Input, Embedding\n",
    "from tensorflow.python.keras.layers import LSTM, GRU\n",
    "from tensorflow.python.keras.layers import Dropout, BatchNormalization, Activation, TimeDistributed, Masking\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D, Conv2D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = 100 # number of objects\n",
    "N_days = 50 #101\n",
    "Nf = 6 # number of filters\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you can load in PLAsTiCC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 8\n",
    "\n",
    "data_dir = '/scratch/[YOUR INFO]'\n",
    "data_extension = '_minmax_yspline_yt0_multiclass_maybefullci()_zNone_bTrue_ig(88,92,65,16,53,6).npy'\n",
    "\n",
    "# Read in dataset\n",
    "_lc_data = np.load(data_dir + 'X_train' + data_extension)\n",
    "_wgt_map = np.load(data_dir + 'X_wgtmap_train' + data_extension)\n",
    "_pre_mask_map = np.ma.masked_values(_lc_data, 0)\n",
    "_mask_map = np.ones(np.shape(_lc_data))\n",
    "_mask_map[_pre_mask_map.mask] = 0.0\n",
    "\n",
    "label = np.load(data_dir + 'y_train' + data_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can instead load in the test data in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 4\n",
    "\n",
    "label = np.load('label.npy')\n",
    "lc_data = np.load('lc_data.npy')\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(label, num_classes=num_class, dtype=\"float64\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((_lc_data, label[:, -1, :])) #(lc_data, labels))\n",
    "batch_ds = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model using tf.Sequential.\n",
    "Compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = N_days, Nf, num_class\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(n_timesteps,n_features))) #, return_sequences=True\n",
    "model.add(Dropout(0.0))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.00001)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit for the model weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(batch_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
